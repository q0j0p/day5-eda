{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis (EDA)\n",
    "\n",
    "Approaching EDA systematically is important to ensure that you don't forget any steps and avoid making errors which could compromise your analysis/modeling later.  Before starting EDA, you should have defined the business question and understand what data sources are available.  During EDA, you want to refine your intuition about the data and develop hypotheses which we could model or test later.\n",
    "\n",
    "Note how at each step, I keep checking that everything worked as expected.\n",
    "\n",
    "We will perform the following steps:\n",
    "\n",
    "*  Load data\n",
    "*  Sanity check data\n",
    "*  Summary statistics\n",
    "*  Plots\n",
    "*  Identify and examine problem data\n",
    "   *  Outliers\n",
    "   *  Missing data\n",
    "*  Clean data\n",
    "*  First crappy model\n",
    "\n",
    "After EDA, it is time to peform cleaning for more intensive modeling, engineer features, and refine the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Everything starts with loading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', \n",
    "                      names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checking\n",
    "\n",
    "After loading the data, you need to check that the data loaded correctly.  If you are working with a large dataset, create a subset so that you can quickly get everything working.  Later, rerun with the full data or larger subsamples.  Make sure that the subsamples are representative by trying multiple subsamples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that data types are correct and if there any data is missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the `species` to a categorical variable: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.species = df.species.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check conversion was successful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great!  Everything is now the correct data type.  And, we are fortunate not to have any missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I like to tabulate (1-way and 2-way) categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.species.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the data is ready for the next step: summary statistics.  Note:  there is no class imbalance.  If there were, we would have to think about up/down sampling or weighting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary statistics\n",
    "\n",
    "Next, I look at summary statistics. I want to understand the nature of the variation and whether there are any problems, such as outliers or missing values.  You may decide to plot at this stage as well -- histograms and box plots are particularly useful.  You may also decide to compute statistics for subsets of the data based on some categorical field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the classic statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data is very skewed or has kurtosis, you might want to check other percentiles or statistics.  Or, check for departures from normality.  Big data, such as Amazon data, often has a long tail, so you may need to transform data during feature engineering, such as by taking `log`s of fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that statistics look different for each species so that we have a chance of predicting species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby('species').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "\n",
    "Summary statistics can be misleading, as Anscomb showed with his [Quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet).  Consequently, you should always plot (a subset) of your data to develop intuition and hypotheses about the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I like to start by plotting the features against each other to better understand the variation in the data.  If you have a lot of features, you will need to chose the sensible subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "scatter_matrix(df, alpha=0.3, c=df.species.cat.codes, figsize=(16,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots make us hopeful that the variation in the data will be able to predict the different species.  I like to start with box plots which graphically show the mean, median, quartiles, and outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot(kind='box', figsize=(9,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only `sepal_width` has outliers, but they are not extremely extreme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.plot(bins=25, alpha=0.2, kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data seems to have good variation, but it looks like there might be a mass point around `0` for `petal_width`.  Let's look into that in more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.petal_width.plot(bins=25, alpha=0.3, kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might need to talk to a domain expert (biologist) about this. Or, it could be different species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby('species').hist('petal_width', bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split in the histogram of `petal_width` appears to be caused by the iris's species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine bad data\n",
    "\n",
    "It is important to identify outliers and missing values, and then make a sensible decision about how to deal with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers\n",
    "\n",
    "We saw from the box plots that only `sepal_width` has outliers.  Some options are:\n",
    "\n",
    "*  Drop them\n",
    "*  Use them unchanged\n",
    "*  Bin the continuous feature and add a bin for outliers (Check out `pd.cut` and `pd.get_dummies` for this case)\n",
    "*  [Winsorize](https://en.wikipedia.org/wiki/Winsorising) the outliers\n",
    "*  Truncate or impute the outliers in some other sensible manner\n",
    "*  Check if some other factor is causing outliers, such as defects in telemetry/instrumentation\n",
    "\n",
    "In the current case, using them unchanges is reasonable because the outliers are not very extreme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data\n",
    "\n",
    "Similarly, you need to identify missing values and decide how to deal with them.  There are a couple options:\n",
    "\n",
    "*  Drop rows with missing data if it is *missing at random* (How would you test this?)\n",
    "*  Impute missing values\n",
    "*  Bin the feature and add a bin for missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data\n",
    "\n",
    "Be very careful when cleaning data not to lose information which has predictive power.  It is very helpful to discuss cleaning and feature engineering with a domain expert.  Fortunately, this data doesn't need any further cleaning.  Often, you will have to identify and construct a label/target which makes sense and engineer other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a crappy first model\n",
    "\n",
    "At this step, you want to check that your pipeline works and modeling is likely to succeed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.icol(range(4))\n",
    "y = df.icol(4)\n",
    "y = y.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegressionCV(cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be suspicious of results which are too good.  If you observe them, you need to check for **information leakage**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[y != y_hat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final remarks\n",
    "\n",
    "EDA, cleaning, feature engineering, and modeling are an interative process.  At each step, you might discover something you missed and need to return to an earlier step.  Ultimately, understanding your data's strengths and weaknesses and engineering good features is usually more important that what model you choose.\n",
    "\n",
    "Now, you should focu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
